<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Classifier</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
    <h1>Upload an Image for Classification</h1>
    <input type="file" id="image-upload" accept="image/*">
    <button onclick="loadAndClassifyImage()">Classify Image</button>
    <br>
    <img id="image-preview" style="max-width: 300px;" alt="Uploaded Image">
    <p id="classification-result"></p>

    <script>
        let session;
        const classDict = {
            0: "Bayi sepertinya mengalami kelelahan.\nPerbanyak istirahat dan makan yang cukup.",
            1: "Bayi menangis tanda terdapat keadaan yang tidak nyaman.\nHal ini bisa disebabkan rasa nyeri atau sesak pada bayi.\nHubungi dokter segera!",
            2: "Bayi mengalami demam.\nSegera beri obat penurun panas",
            3: "Bayi dalam foto terlihat sehat."
        };

        async function loadModel() {
            console.log('Loading ONNX model...');
            session = await ort.InferenceSession.create('/best.onnx');
            console.log('Model loaded');
        }

        function loadAndClassifyImage() {
            const fileInput = document.getElementById('image-upload');
            const file = fileInput.files[0];
            if (!file) {
                alert("Please select an image file.");
                return;
            }

            const reader = new FileReader();
            reader.onload = async function(e) {
                const imageData = e.target.result;
                document.getElementById('image-preview').src = imageData;
                const image = await loadImage(imageData);
                classifyImage(image);
            };
            reader.readAsDataURL(file);
        }

        async function loadImage(src) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = src;
            });
        }

        async function classifyImage(img) {
    const tensor = preprocessImage(img);
    const outputs = await session.run({[session.inputNames[0]]: tensor});
    const outputTensor = outputs[Object.keys(outputs)[0]]; // Assuming model has one output

    // Access the data from the tensor
    const outputData = outputTensor.data;
    
    const maxConfidenceIndex = outputData.indexOf(Math.max(...outputData));
    console.log(outputData)
    if(Math.max(...outputData)<0.4){
        document.getElementById('classification-result').textContent = "Classification Result: " + "Gambar tidak valid. Mohon ambil ulang gambar bayi!";
    }else{
      const message = classDict[maxConfidenceIndex] || "No valid prediction";
    document.getElementById('classification-result').textContent = "Classification Result: " + message;  
    }
    
}


        function preprocessImage(img) {
    const width = 640;
    const height = 640;
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    canvas.width = width;
    canvas.height = height;
    ctx.drawImage(img, 0, 0, width, height);
    const imageData = ctx.getImageData(0, 0, width, height);

    // Flatten the pixel data and normalize
    const data = Float32Array.from(imageData.data, d => d / 255.0);

    // Rearrange the data to [N, C, H, W]
    // ImageData is in RGBA, we need to remove the alpha channel and then reorder
    const channels = 3; // We are ignoring the alpha channel
    const tensor = new Float32Array(width * height * channels);
    let index = 0;
    for (let i = 0; i < data.length; i += 4) {
        // R, G, B
        tensor[index++] = data[i];     // R
        tensor[index++] = data[i + 1]; // G
        tensor[index++] = data[i + 2]; // B
    }

    return new ort.Tensor('float32', tensor, [1, channels, height, width]);
}


        window.onload = loadModel;
    </script>
</body>
</html>
